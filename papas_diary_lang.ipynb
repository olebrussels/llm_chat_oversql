{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae0f3a9-4e0c-4173-b616-15f03f49f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Alias _set_env to set_env\n",
    "set_env = _set_env\n",
    "\n",
    "set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15383584",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"diary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6637a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0700dd50-1dcc-4a0f-b773-fead95292136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['diary_entries']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///diary.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409472d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine  # Import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from create_diary_schema import DiaryEntry\n",
    "\n",
    "# Connect to the SQLite database\n",
    "engine = create_engine(\"sqlite:///diary.db\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d96647f4-2e40-4c77-a2b3-fb14e6da1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba61d0e-e1ac-44f4-a3dc-9e39391e4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "165b1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 2\n",
    "for message in query_prompt_template.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c8e6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44e3ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT date FROM diary_entries ORDER BY date ASC LIMIT 1;'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"when was the first entry?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66331589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ef4b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(115,)]'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": \"SELECT COUNT(*) AS total_entries FROM diary_entries;\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86d2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5c21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m[ 3][t 0][1747383616.238782167][Client.cpp:600]\tCreate client 1\u001b[0m\n",
      "\u001b[1;36m[ 3][t 0][1747383616.239383935][Client.cpp:383]\tInitialize client 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from telegram.client import Telegram\n",
    "\n",
    "tg = Telegram(\n",
    "    api_id=26621694,\n",
    "    api_hash='d5ca85e3ee9c5232b3a7afc537c59452',\n",
    "    phone='+32484834767',\n",
    "    database_encryption_key='BRU0109al',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[ 2][t 1][1747383621.567258358][TdDb.cpp:431][#1][!RunOnSchedulerWorker]\tSet PRAGMA user_version = 14\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383621.603837251][AuthDataShared.cpp:118][#1][!Td]\tDcId{1} [auth_key_id:0][state:Empty][created_at:0][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383621.611803054][Session.cpp:271][#1][!SessionProxy:1:main]\tGenerate new session_id 5938941892111441128 for auth key 0 for main DC1\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383623.981846094][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{1} [auth_key_id:18152386545803320846][state:NoAuth][created_at:1747383622][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383623.981880903][Session.cpp:1422][#1][!Session:1:main]\tUpdate auth key in session_id 5938941892111441128 to 18152386545803320846\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383624.187990427][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{4} [auth_key_id:0][state:Empty][created_at:0][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383624.189968347][Session.cpp:271][#1][!SessionProxy:4:main]\tGenerate new session_id 8816244465301331510 for auth key 0 for main DC4\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383625.362587690][AuthDataShared.cpp:118][#1][!Session:4:main]\tDcId{4} [auth_key_id:16986672786885447469][state:NoAuth][created_at:1747383624][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383625.362618207][Session.cpp:1422][#1][!Session:4:main]\tUpdate auth key in session_id 8816244465301331510 to 16986672786885447469\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383637.171882152][AuthDataShared.cpp:118][#1][!Session:4:main]\tDcId{4} [auth_key_id:16986672786885447469][state:OK][created_at:1747383624][last_used:1747500624]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AuthorizationState.READY: 'authorizationStateReady'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[ 2][t 4][1747383637.333762407][Session.cpp:271][#1][!SessionProxy:1:main]\tGenerate new session_id 7971521895533597407 for auth key 18152386545803320846 for DC1\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747383637.599404811][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{1} [auth_key_id:18152386545803320846][state:OK][created_at:1747383622][last_used:1747500623]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tg.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9e3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@type': 'chats', 'total_count': 93, 'chat_ids': [777000, 6822025926, -1001619831579, -4762585149, 1771869684, 7816829551, 7846382525, 57098707, -1002340503783, 7954296876, 1241442881, 7069489447, 8078951456, 7801784533, -857213611, 7595113840, -1001895831685, 735511181, 7712627342, 7120032145, 7870468219, 6597325114, 7591611458, 7672348965, -4017208805, 7662181205, -4150664340, 7945116301, 1144008385, 6163574533, 7878237007, 6758663599, 7129916042, 7525131981, 7401048146, 7127173154, 7152100632, 7019764895, 7298823424, 7247728024, 6381639412, 7076346379, 7176466021, 7028967332, 7192362684, 7084784023, 7106241006, 1318953231, 7150614755, 889765482, 7197974963, 7056847755, 6441630674, 6952861107, 1530754544, 6856322095, 6633835366, 6976665394, 6686797836, 6709461690, 6533868226, 6943892037, 6772438286, -4014980841, -4081098759, 6678459433, 6638828584, 6505532685, 6414335330, 6764866171, 6454772031, 6928544385, 6663733510, 6531836133, 6465153473, 6631804287, 6622357982, 6097187659, 1097152571, 6493846692, 6631633135, 6379008982, 5946405269, 6183973075, 6137483622, 1423978801, 5742266069, 773921122, 5888167752, 6183535329, 6236239477, 5817967907, 1004114443], '@extra': {'request_id': 'e166dfe1682f4454855fb1dcda382639'}}\n"
     ]
    }
   ],
   "source": [
    "result = tg.get_chats()\n",
    "result.wait()\n",
    "print(result.update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<telegram.utils.AsyncResult at 0x7f24a428a190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chat_id = -4762585149\n",
    "\n",
    "#tg.send_message(\n",
    "#            chat_id=chat_id,\n",
    "#            text='test',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0c086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_to_telegram(state: State):\n",
    "    \"\"\"Post the generated answer to Telegram.\"\"\"\n",
    "    chat_id = -4762585149 # Replace with the desired chat ID\n",
    "    message = state[\"answer\"]  # Use the answer from the state\n",
    "    try:\n",
    "        tg.send_message(chat_id=chat_id, text=message)\n",
    "        return {\"answer\": state[\"answer\"], \"status\": \"Message sent\"}  # Update the state\n",
    "    except Exception as e:\n",
    "        return {\"answer\": state[\"answer\"], \"status\": f\"Failed to send message: {str(e)}\"}  # Update the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb955136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"write_query\", write_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"post_to_telegram\", post_to_telegram)  # Add the new node\n",
    "\n",
    "workflow.add_edge(START, \"write_query\")\n",
    "workflow.add_edge(\"write_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", \"post_to_telegram\")  # Connect the new node\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = workflow.compile(interrupt_before=[\"post_to_telegram\"], checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf412aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[ 2][t 4][1747319008.432404518][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{1} [auth_key_id:5306460131041795999][state:OK][created_at:1747318991][last_used:1747435992]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Metadata Overview:\n",
      "write_query: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'write_query': {'query': \"SELECT id, date FROM diary_entries WHERE content='hi i am manuel, the owner of the diary' LIMIT 10;\"}}\n",
      "Chunk Metadata Overview:\n",
      "execute_query: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'execute_query': {'result': ''}}\n",
      "Chunk Metadata Overview:\n",
      "generate_answer: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'generate_answer': {'answer': 'The SQL result has not been provided, but based on the user question and SQL query, if the query has returned results, it would indicate that there exists a diary entry with the exact content \"hi i am manuel, the owner of the diary.\" \\n\\nIf there are results, you can answer the user with the relevant id and date of the diary entry. If there are no results, then you would inform the user that there are no entries that match the provided content. \\n\\nWould you like to specify the results to get a more detailed response?'}}\n",
      "Chunk Metadata Overview:\n",
      "__interrupt__: <class 'tuple'>\n",
      "Detailed Chunk Content:\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "#config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "#initial_input = {\"question\": HumanMessage(content=\"hi i am manuel, the owner of the diary\")}\n",
    "\n",
    "#for chunk in graph.stream(initial_input, config, stream_mode=\"updates\"):\n",
    "#    print(\"Chunk Metadata Overview:\")\n",
    "#    for key, value in chunk.items():\n",
    "#        print(f\"{key}: {type(value)}\")\n",
    "#    print(\"Detailed Chunk Content:\")\n",
    "#    print(chunk)\n",
    "\n",
    "# Stream updates\n",
    "#for chunk in graph.stream(initial_input, config, stream_mode=\"values\"):\n",
    "#    chunk[\"answer\"].pretty_print()\n",
    "#    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0dab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT content FROM diary_entries ORDER BY date DESC LIMIT 10;'}}\n",
      "{'execute_query': {'result': '[(\\'In the meditation this morning, I become aware of the extreme fragility of my attention, of my freedom, of my peace. I try to focus on the here and now, and my mind goes constantly without me, allowing it towards productivity. I need to learn to stay less on my mind, on my own abstractions, and...\\',), (\\'Every day. The song of the clock, of the bell of the Church of Bridgetines, which is close to high place, reminds me of my committed to ground. Stop traveling with my heads and go into the concrete. Connect with real people with real problems, try to solve them. Stop dreaming and the biggest...\\',), (\"Today is 10th of May. Good morning. Dear Diary, I had a good night\\'s sleep and I feel refreshed. I\\'m in the terrace. It\\'s almost 8 o\\' clock in the morning. I hear a sound already from works outside. Somebody must be cutting some trees or some leaves or cleaning something. It\\'s a bit early, but...\",), (\"Today is 9th of May. I went to the birthday of Mike. It\\'s always difficult to from time to time go to his place because I meet old friends with whom I lost touch. There\\'s nothing wrong with them and I don\\'t have any negative feeling towards them, but I just don\\'t see them anymore. We went...\",), (\"Today is May 8, it\\'s in the morning and I had a very weird night. I woke up in the middle of the night and I was feeling my body super warm, like very hot, strangely hot, like fever. Then I went back to sleep and I had a dream about. I had to go back to university, to Santiago de Compostela, to...\",), (\"I was sick yesterday. I had stomach problems. It was Tuesday and it was two days after a big party on Saturday and I was feeling like with nausea and I wanted to vomit. And so today is Wednesday was a bit better, but still was not 100%. And now it\\'s in the evening and I\\'m starting to feel a...\",), (\\'I need to stop treating Hogne like I know the right way of doing things. Paternalistic, superior thinking. Today I wanted her to let me take full care of the dinner preparation, including Adas. And she insisted in preparing the meal for Ada herself. And she was bothering me, she was bothering me...\\',), (\"It\\'s Friday, 2nd of May, 2025, and there are a couple of things in my head. I am having a drink on my own in Place de Je d\\'val, this square of the neighborhood in which I have been living for 20 years now. There has been so many things happening in this neighborhood. By recording, I want to make...\",), (\"Today is Tuesday 29th of April. It\\'s 6 o\\'clock in the morning. I had a difficult night. I slept well on the parts of deep sleep. So at the beginning of the night, on the first four, five, six hours, and I think this is enough to get a basic rest. But then in the second part of my sleep, when you...\",), (\"It\\'s Saturday. Saturday, 26th of April and I would like to have a moment of connection with you my dear diary. I am sitting in Maset Terrace and I am on my own. I put Ada on the gym and I\\'m waiting for half an hour to pick her up again and. And then I will go to the reef meeting to discuss about...\",)]'}}\n",
      "Generated Answer:\n",
      "he estado reflexionando mucho últimamente sobre lo frágil que es mi atención y paz. he intentado concentrarme más en el presente y conectar con las personas reales, dejar de soñar tanto. hace poco, fui al cumple de mike, que fue un momento raro porque volví a encontrar a viejos amigos. también he tenido un par de días difíciles, estuve enfermo con problemas de estómago, pero ahora me siento un poco mejor. estoy tratando de ser menos controlador con hogne y dejarla hacer las cosas a su manera. me gusta pasar tiempo en mi terraza y disfrutar de los pequeños momentos.\n",
      "{'generate_answer': {'answer': 'he estado reflexionando mucho últimamente sobre lo frágil que es mi atención y paz. he intentado concentrarme más en el presente y conectar con las personas reales, dejar de soñar tanto. hace poco, fui al cumple de mike, que fue un momento raro porque volví a encontrar a viejos amigos. también he tenido un par de días difíciles, estuve enfermo con problemas de estómago, pero ahora me siento un poco mejor. estoy tratando de ser menos controlador con hogne y dejarla hacer las cosas a su manera. me gusta pasar tiempo en mi terraza y disfrutar de los pequeños momentos.'}}\n",
      "{'__interrupt__': ()}\n",
      "Operation cancelled by user.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\"configurable\": {\"thread_id\": \"34\"}}\n",
    "\n",
    "initial_input = {\n",
    "    \"question\": HumanMessage(\n",
    "        content=(\n",
    "            \"you are a diary drafting assistant with access to my diary entries. \"\n",
    "            \"\"\n",
    "            \"i would like you to send life updates to my friend Concha in spanish\"\n",
    "            \"please use some facts of things i have done in the last 2 months including birthday at mike's\"\n",
    "            \"draft a short message summarizing what is going on in my life based on latest diary entries. \"\n",
    "            \"please only use the content of the entries to generate the answer. \"\n",
    "            \"do not include any system message nor AI message in the generated answer, just the content of the entries.\"\n",
    "            \"do not include capital letters in the message. \"\n",
    "            \"do make 1 mistake in spelling in the message. \"\n",
    "            \"please speak as if you were me and you are speaking directly to my parents. \"\n",
    "            \"please use coloquial spanish from spain \"\n",
    "            \"please do not mention any dates in the message. just speak as if is today\"\n",
    "            \"do not include introduction sentence. this is going to be a telegram message.\"\n",
    "        )\n",
    "    )\n",
    "}\n",
    "\n",
    "# Stream through the graph until the interrupt\n",
    "for step in graph.stream(initial_input, config, stream_mode=\"updates\"):\n",
    "    if \"generate_answer\" in step:  # Check if the generate_answer node is reached\n",
    "        print(\"Generated Answer:\")\n",
    "        print(step[\"generate_answer\"][\"answer\"])  # Display the answer to the user\n",
    "    print(step)\n",
    "\n",
    "# Ask for user approval to send the message\n",
    "user_approval = input(\"Do you want to send this answer to Telegram? (yes/no): \")\n",
    "\n",
    "# Check user approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    # Continue the graph execution to send the message\n",
    "    for step in graph.stream(None, config, stream_mode=\"values\"):\n",
    "        if \"post_to_telegram\" in step:  # Check if the post_to_telegram node is reached\n",
    "            print(\"Message sent to Telegram.\")\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yc_final 3.9 (venv)",
   "language": "python",
   "name": "venv-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
