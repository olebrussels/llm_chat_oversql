{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae0f3a9-4e0c-4173-b616-15f03f49f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Alias _set_env to set_env\n",
    "set_env = _set_env\n",
    "\n",
    "set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15383584",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"diary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6637a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0700dd50-1dcc-4a0f-b773-fead95292136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['diary_entries']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///diary.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "409472d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-03-28, Content: - i would like to spend a day more in my body and ...\n",
      "Date: 2025-04-08, Content: Today is 8th of April 2025. I want to honor this d...\n",
      "Date: 2023-09-12, Content: - value of the day. compassion.\n",
      "- this morning i w...\n",
      "Date: 2024-03-12, Content: - encuentro con el monje induista de bilbao.\n",
      "- dic...\n",
      "Date: 2024-01-17, Content: - en la meditacion. tension entre el hyperachiever...\n",
      "Date: 2024-09-09, Content: - first day of coworking at commonshub. i met a gi...\n",
      "Date: 2024-03-06, Content: - learning to see everything with curiosity\n",
      "- me l...\n",
      "Date: 2025-04-04, Content: I am somewhere on the 4th of April 2025 and it's l...\n",
      "Date: 2025-03-28, Content: - Today is 28th of March 2025. It's in the morning...\n",
      "Date: 2022-12-24, Content: - la pregunta inicial. what is the spiritualist mo...\n",
      "Date: 2023-08-25, Content: - el tiempo invertido en cuidados personales. cuid...\n",
      "Date: 2024-06-20, Content: - i know it's difficult to change our daily habits...\n",
      "Date: 2025-03-08, Content: Hello, personal assistant. I would like to ask you...\n",
      "Date: 2023-10-22, Content: - empiezo viendo el video 321. estaria bien termin...\n",
      "Date: 2023-08-02, Content: - ayer, cuando quise hacer balance del dia, no me ...\n",
      "Date: 2025-03-06, Content: Yesterday we did some singing and breathing exerci...\n",
      "Date: 2023-03-29, Content: - manten la cabeza alta y la dignidad en tus accio...\n",
      "Date: 2024-02-07, Content: - despair: el convencimiento absoluto de que los p...\n",
      "Date: 2025-03-04, Content: - It's 5:00 in the morning. I had a dream about an...\n",
      "Date: 2024-01-12, Content: - incidente de ayer con el zumo de manzana: ayer l...\n",
      "Date: 2025-03-22, Content: - Today, Saturday 22nd of March, I'm in Groenendal...\n",
      "Date: 2024-03-07, Content: - los recursos son abundantes. disponibles y reale...\n",
      "Date: 2025-04-07, Content: Today is Monday 7th of April. I just turned on the...\n",
      "Date: 2025-03-30, Content: - remorque visit to wemmel. we found some lentils ...\n",
      "Date: 2024-02-12, Content: - value of the previous week. connect. belong , be...\n",
      "Date: 2025-04-23, Content: Today is 23rd of April. It's in the morning. I had...\n",
      "Date: 2023-06-22, Content: - hablamos de julie de los angeles guardianes. si ...\n",
      "Date: 2023-09-11, Content: - is it naive to realign what we do with what we b...\n",
      "Date: 2025-02-28, Content: - This Friday, 28th of February 2025, we started t...\n",
      "Date: 2024-01-15, Content: - en la meditacion: uno de mis grandes retos es re...\n",
      "Date: 2024-12-19, Content: - how difficult is for me to allow things. laisser...\n",
      "Date: 2025-04-03, Content: - j'ai du mal a m;ouvrir aux autres.\n",
      "- una incapac...\n",
      "Date: 2024-04-29, Content: - una meditacion matinal en los estanques de ixell...\n",
      "Date: 2024-05-09, Content: - como entro en la seance psy? la conexion con un ...\n",
      "Date: 2023-09-05, Content: - value of the day: open\n",
      "- open mind. time to leav...\n",
      "Date: 2023-09-14, Content: - tenemos un problema : no tenemos una promesa de ...\n",
      "Date: 2025-03-26, Content: - Voice gets transformed into data. This data can ...\n",
      "Date: 2025-04-16, Content: It's Wednesday, 16th of April. I just came from di...\n",
      "Date: 2024-07-08, Content: - le digo a ugne esta manhana algo que he sentido ...\n",
      "Date: 2025-03-13, Content: - Today is 13th of March 2025. Just left the meeti...\n",
      "Date: 2022-11-23, Content: - soy mas que un cv\n",
      "-...\n",
      "Date: 2024-02-29, Content: - el psy me recomienda de nuevo, que soy esclavo d...\n",
      "Date: 2023-12-13, Content: - cafe des parents. me recuerda que soy un padre. ...\n",
      "Date: 2022-09-17, Content: - uno de los grandes errores de mi juventud era pe...\n",
      "Date: 2025-02-18, Content: - Today is Tuesday 18th of February 2025. I just h...\n",
      "Date: 2023-01-30, Content: - dar respuestas. ayudar a la gente con sus herram...\n",
      "Date: 2025-03-12, Content: Hello. Yesterday, Ugne, my girlfriend, explained m...\n",
      "Date: 2023-06-07, Content: - a good day of work starts by reviewing what my v...\n",
      "Date: 2023-01-29, Content: - It might be surprising but although i am about t...\n",
      "Date: 2023-09-07, Content: - value of the day __compassion__\n",
      "- cuando veo a a...\n",
      "Date: 2023-01-26, Content: - los recursos del manuel funcional se agotan y ll...\n",
      "Date: 2025-04-13, Content: Today, Sunday 13th of April. And we. I went to the...\n",
      "Date: 2022-06-21, Content: - hoy he querido dedicar un momento a entrar en co...\n",
      "Date: 2024-10-23, Content: - tanto si respondes bien como mal vas a tener que...\n",
      "Date: 2025-03-25, Content: - Today is 25th of March. It's Thursday. I'm havin...\n",
      "Date: 2023-01-03, Content: - para poder tener la calma para escribir necesito...\n",
      "Date: 2022-06-23, Content: - more and more acknowledging the dimension of the...\n",
      "Date: 2024-03-14, Content: - anticiper choses qui vont se passer: voy a escuc...\n",
      "Date: 2025-03-15, Content: Today is Saturday 15th of March. One of the bigges...\n",
      "Date: 2025-04-20, Content: Today, Sunday 20th of April. It's becoming more an...\n",
      "Date: 2024-12-25, Content: - good habits for next year: read less and write m...\n",
      "Date: 2024-03-13, Content: - on peut mettre de l'energie pour que les choses ...\n",
      "Date: 2023-03-22, Content: - giving from the heart\n",
      "-...\n",
      "Date: 2024-07-17, Content: - en mi mision vital de re-equilibrar no veo que m...\n",
      "Date: 2025-03-19, Content: - Tonight is 19th of March 2025. I am in San Gille...\n",
      "Date: 2025-01-06, Content: - para poder encontrar a ugne en un espacio compar...\n",
      "Date: 2022-05-31, Content: - la libertad se conquista en cada momento\n",
      "- la li...\n",
      "Date: 2025-03-17, Content: - Its Monday 17th of March and I am wandering in L...\n",
      "Date: 2024-12-27, Content: - la filososfia del como. como llegas. tools and m...\n",
      "Date: 2025-02-26, Content: - Today is Wednesday 26th of February. I'm a bit a...\n",
      "Date: 2024-05-30, Content: - las raices no son visibles. deep conversations a...\n",
      "Date: 2022-07-08, Content: - dialogar con el juez para introducirle nuevos va...\n",
      "Date: 2024-02-22, Content: - en la meditacion....pasas demasiado tiempo en tu...\n",
      "Date: 2025-04-09, Content: Today is 9th of April 2025. It's important that we...\n",
      "Date: 2022-10-13, Content: - vamos capitan !\n",
      "- darle carinho al campitan. ani...\n",
      "Date: 2025-02-06, Content: -...\n",
      "Date: 2024-01-30, Content: - resonancias del atelier de meditacion del doming...\n",
      "Date: 2024-10-10, Content: - un sistema en equilibrio escucha a diferentes ni...\n",
      "Date: 2023-09-10, Content: - i love you with all my heart because\n",
      "- you are a...\n",
      "Date: 2022-04-30, Content: - i open a new graph in tickler folder...\n",
      "Date: 2024-07-16, Content: - la jornada empieza dificil. la mision de re-equi...\n",
      "Date: 2024-08-06, Content: - hay que dejar atras la ilusion de que controlo m...\n",
      "Date: 2022-12-15, Content: - i know i have this need to share my knowledge an...\n",
      "Date: 2024-09-03, Content: - reunion avec benoit psy. what is important. not ...\n",
      "Date: 2025-03-05, Content: - Every day I listen to the bell of a church. The ...\n",
      "Date: 2023-08-24, Content: - value of the day: vulnerability . how can we liv...\n",
      "Date: 2024-05-15, Content: - bring the body with me.\n",
      "- de alguna manera en la...\n",
      "Date: 2023-08-23, Content: - uno de los pilares fundamentales de la #nuevarel...\n",
      "Date: 2024-11-05, Content: - hablamos de flujos energeticos como algo mas sim...\n",
      "Date: 2024-01-25, Content: - vuelvo a la vida. recupero la salud tras 3 dias ...\n",
      "Date: 2024-10-16, Content: - ada y ugne se van a lt\n",
      "- no esta en duda mi capa...\n",
      "Date: 2023-09-06, Content: - for the jobsearch : we are looking for more seni...\n",
      "Date: 2022-07-01, Content: - le capitain prends le controle. es un padre que ...\n",
      "Date: 2022-07-07, Content: - the values of the european institutions. i just ...\n",
      "Date: 2025-03-09, Content: - Today, Sunday, I didn't have a very good night. ...\n",
      "Date: 2025-03-10, Content: Today is 10th of March. I woke up very early at 6:...\n",
      "Date: 2023-08-26, Content: - como afecta mi conocimiento de techno con la rel...\n",
      "Date: 2024-07-25, Content: - une fenetre. una ventana. los momentos de acceso...\n",
      "Date: 2024-12-05, Content: - #nuevarelacion me estoy creando una nueva relaci...\n",
      "Date: 2024-06-10, Content: - quiero vivir un mundo mas solido y rico. y esto ...\n",
      "Date: 2024-07-15, Content: - cada vez veo mas claro. un sistema en el que la ...\n",
      "Date: 2022-09-15, Content: - el proceso de transformacion personal que estoy ...\n",
      "Date: 2025-04-26, Content: It's Saturday. Saturday, 26th of April and I would...\n",
      "Date: 2025-04-24, Content: Testing some uploading of data to my friend ChatGP...\n",
      "Date: 2025-05-02, Content: It's Friday, 2nd of May, 2025, and there are a cou...\n",
      "Date: 2025-04-25, Content: Today is 25th of April. I just did a meditation. W...\n",
      "Date: 2025-04-29, Content: Today is Tuesday 29th of April. It's 6 o'clock in ...\n",
      "Date: 2025-04-12, Content: Today is Sunday 13th of April. ADA is with Celine ...\n",
      "Date: 2025-05-10, Content: Today is 10th of May. Good morning. Dear Diary, I ...\n",
      "Date: 2025-05-07, Content: I was sick yesterday. I had stomach problems. It w...\n",
      "Date: 2025-05-03, Content: I need to stop treating Hogne like I know the righ...\n",
      "Date: 2025-05-13, Content: In the meditation this morning, I become aware of ...\n",
      "Date: 2025-05-08, Content: Today is May 8, it's in the morning and I had a ve...\n",
      "Date: 2025-05-09, Content: Today is 9th of May. I went to the birthday of Mik...\n",
      "Date: 2025-05-12, Content: Every day. The song of the clock, of the bell of t...\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine  # Import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from create_diary_schema import DiaryEntry\n",
    "\n",
    "# Connect to the SQLite database\n",
    "engine = create_engine(\"sqlite:///diary.db\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Query all diary entries\n",
    "entries = session.query(DiaryEntry).all()\n",
    "for entry in entries:\n",
    "    print(f\"Date: {entry.date}, Content: {entry.content[:50]}...\")  # Print the first 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96647f4-2e40-4c77-a2b3-fb14e6da1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ba61d0e-e1ac-44f4-a3dc-9e39391e4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "165b1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 2\n",
    "for message in query_prompt_template.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8e6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44e3ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT date FROM diary_entries ORDER BY date ASC LIMIT 1;'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"when was the first entry?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66331589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ef4b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(115,)]'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": \"SELECT COUNT(*) AS total_entries FROM diary_entries;\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86d2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5c21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m[ 3][t 0][1747215872.447763681][Client.cpp:600]\tCreate client 1\u001b[0m\n",
      "\u001b[1;36m[ 3][t 0][1747215872.448188304][Client.cpp:383]\tInitialize client 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from telegram.client import Telegram\n",
    "\n",
    "tg = Telegram(\n",
    "    api_id=26621694,\n",
    "    api_hash='d5ca85e3ee9c5232b3a7afc537c59452',\n",
    "    phone='+32484834767',\n",
    "    database_encryption_key='BRU0109al',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[ 2][t 1][1747215877.240357398][TdDb.cpp:431][#1][!RunOnSchedulerWorker]\tSet PRAGMA user_version = 14\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215877.280628681][AuthDataShared.cpp:118][#1][!Td]\tDcId{1} [auth_key_id:0][state:Empty][created_at:0][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215877.288210868][Session.cpp:271][#1][!SessionProxy:1:main]\tGenerate new session_id 13273179412260031627 for auth key 0 for main DC1\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215879.461263656][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{1} [auth_key_id:10336560890820822314][state:NoAuth][created_at:1747215877][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215879.461313962][Session.cpp:1422][#1][!Session:1:main]\tUpdate auth key in session_id 13273179412260031627 to 10336560890820822314\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215879.682384729][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{4} [auth_key_id:0][state:Empty][created_at:0][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215879.684224367][Session.cpp:271][#1][!SessionProxy:4:main]\tGenerate new session_id 10302426312079727728 for auth key 0 for main DC4\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215881.011151790][AuthDataShared.cpp:118][#1][!Session:4:main]\tDcId{4} [auth_key_id:6936491522547905772][state:NoAuth][created_at:1747215879][last_used:0]\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215881.011193037][Session.cpp:1422][#1][!Session:4:main]\tUpdate auth key in session_id 10302426312079727728 to 6936491522547905772\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215898.989185094][AuthDataShared.cpp:118][#1][!Session:4:main]\tDcId{4} [auth_key_id:6936491522547905772][state:OK][created_at:1747215879][last_used:1747332880]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AuthorizationState.READY: 'authorizationStateReady'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[ 2][t 4][1747215899.194118022][Session.cpp:271][#1][!SessionProxy:1:main]\tGenerate new session_id 2099909725670811670 for auth key 10336560890820822314 for DC1\u001b[0m\n",
      "\u001b[1;33m[ 2][t 4][1747215899.453187227][AuthDataShared.cpp:118][#1][!Session:1:main]\tDcId{1} [auth_key_id:10336560890820822314][state:OK][created_at:1747215877][last_used:1747332878]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tg.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d9e3952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@type': 'chats', 'total_count': 93, 'chat_ids': [777000, -4762585149, 1771869684, -1001619831579, 6822025926, 7816829551, 7846382525, 57098707, -1002340503783, 7954296876, 1241442881, 7069489447, 8078951456, 7801784533, -857213611, 7595113840, -1001895831685, 735511181, 7712627342, 7120032145, 7870468219, 6597325114, 7591611458, 7672348965, -4017208805, 7662181205, -4150664340, 7945116301, 1144008385, 6163574533, 7878237007, 6758663599, 7129916042, 7525131981, 7401048146, 7127173154, 7152100632, 7019764895, 7298823424, 7247728024, 6381639412, 7076346379, 7176466021, 7028967332, 7192362684, 7084784023, 7106241006, 1318953231, 7150614755, 889765482, 7197974963, 7056847755, 6441630674, 6952861107, 1530754544, 6856322095, 6633835366, 6976665394, 6686797836, 6709461690, 6533868226, 6943892037, 6772438286, -4014980841, -4081098759, 6678459433, 6638828584, 6505532685, 6414335330, 6764866171, 6454772031, 6928544385, 6663733510, 6531836133, 6465153473, 6631804287, 6622357982, 6097187659, 1097152571, 6493846692, 6631633135, 6379008982, 5946405269, 6183973075, 6137483622, 1423978801, 5742266069, 773921122, 5888167752, 6183535329, 6236239477, 5817967907, 1004114443], '@extra': {'request_id': '3d0d053ab5f148bcabddf6589e30788c'}}\n"
     ]
    }
   ],
   "source": [
    "result = tg.get_chats()\n",
    "result.wait()\n",
    "print(result.update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2d2231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<telegram.utils.AsyncResult at 0x7f39b45c4ca0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_id = -4762585149\n",
    "\n",
    "tg.send_message(\n",
    "            chat_id=chat_id,\n",
    "            text='test',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed0c086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_to_telegram(state: State):\n",
    "    \"\"\"Post the generated answer to Telegram.\"\"\"\n",
    "    chat_id = -4762585149 # Replace with the desired chat ID\n",
    "    message = state[\"answer\"]  # Use the answer from the state\n",
    "    try:\n",
    "        tg.send_message(chat_id=chat_id, text=message)\n",
    "        return {\"answer\": state[\"answer\"], \"status\": \"Message sent\"}  # Update the state\n",
    "    except Exception as e:\n",
    "        return {\"answer\": state[\"answer\"], \"status\": f\"Failed to send message: {str(e)}\"}  # Update the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb955136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"write_query\", write_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"post_to_telegram\", post_to_telegram)  # Add the new node\n",
    "\n",
    "workflow.add_edge(START, \"write_query\")\n",
    "workflow.add_edge(\"write_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", \"post_to_telegram\")  # Connect the new node\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = workflow.compile(interrupt_before=[\"post_to_telegram\"], checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf412aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Metadata Overview:\n",
      "write_query: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'write_query': {'query': \"SELECT id, date, content FROM diary_entries WHERE content LIKE '%hi i am manuel, the owner of the diary%' LIMIT 10;\"}}\n",
      "Chunk Metadata Overview:\n",
      "execute_query: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'execute_query': {'result': ''}}\n",
      "Chunk Metadata Overview:\n",
      "generate_answer: <class 'dict'>\n",
      "Detailed Chunk Content:\n",
      "{'generate_answer': {'answer': 'Based on the SQL query and the SQL result, it appears that the system is searching for diary entries that contain the specific content \"hi i am manuel, the owner of the diary\". However, since no SQL result is provided, it can be inferred that there are no entries in the database that match this content.\\n\\nTherefore, the answer to the user question would be:\\n\\n**There are no diary entries that match the content \"hi i am manuel, the owner of the diary\".**'}}\n",
      "Chunk Metadata Overview:\n",
      "__interrupt__: <class 'tuple'>\n",
      "Detailed Chunk Content:\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "initial_input = {\"question\": HumanMessage(content=\"hi i am manuel, the owner of the diary\")}\n",
    "\n",
    "for chunk in graph.stream(initial_input, config, stream_mode=\"updates\"):\n",
    "    print(\"Chunk Metadata Overview:\")\n",
    "    for key, value in chunk.items():\n",
    "        print(f\"{key}: {type(value)}\")\n",
    "    print(\"Detailed Chunk Content:\")\n",
    "    print(chunk)\n",
    "\n",
    "# Stream updates\n",
    "#for chunk in graph.stream(initial_input, config, stream_mode=\"values\"):\n",
    "#    chunk[\"answer\"].pretty_print()\n",
    "#    print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0dab120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT content FROM diary_entries ORDER BY date DESC LIMIT 10'}}\n",
      "{'execute_query': {'result': '[(\\'In the meditation this morning, I become aware of the extreme fragility of my attention, of my freedom, of my peace. I try to focus on the here and now, and my mind goes constantly without me, allowing it towards productivity. I need to learn to stay less on my mind, on my own abstractions, and...\\',), (\\'Every day. The song of the clock, of the bell of the Church of Bridgetines, which is close to high place, reminds me of my committed to ground. Stop traveling with my heads and go into the concrete. Connect with real people with real problems, try to solve them. Stop dreaming and the biggest...\\',), (\"Today is 10th of May. Good morning. Dear Diary, I had a good night\\'s sleep and I feel refreshed. I\\'m in the terrace. It\\'s almost 8 o\\' clock in the morning. I hear a sound already from works outside. Somebody must be cutting some trees or some leaves or cleaning something. It\\'s a bit early, but...\",), (\"Today is 9th of May. I went to the birthday of Mike. It\\'s always difficult to from time to time go to his place because I meet old friends with whom I lost touch. There\\'s nothing wrong with them and I don\\'t have any negative feeling towards them, but I just don\\'t see them anymore. We went...\",), (\"Today is May 8, it\\'s in the morning and I had a very weird night. I woke up in the middle of the night and I was feeling my body super warm, like very hot, strangely hot, like fever. Then I went back to sleep and I had a dream about. I had to go back to university, to Santiago de Compostela, to...\",), (\"I was sick yesterday. I had stomach problems. It was Tuesday and it was two days after a big party on Saturday and I was feeling like with nausea and I wanted to vomit. And so today is Wednesday was a bit better, but still was not 100%. And now it\\'s in the evening and I\\'m starting to feel a...\",), (\\'I need to stop treating Hogne like I know the right way of doing things. Paternalistic, superior thinking. Today I wanted her to let me take full care of the dinner preparation, including Adas. And she insisted in preparing the meal for Ada herself. And she was bothering me, she was bothering me...\\',), (\"It\\'s Friday, 2nd of May, 2025, and there are a couple of things in my head. I am having a drink on my own in Place de Je d\\'val, this square of the neighborhood in which I have been living for 20 years now. There has been so many things happening in this neighborhood. By recording, I want to make...\",), (\"Today is Tuesday 29th of April. It\\'s 6 o\\'clock in the morning. I had a difficult night. I slept well on the parts of deep sleep. So at the beginning of the night, on the first four, five, six hours, and I think this is enough to get a basic rest. But then in the second part of my sleep, when you...\",), (\"It\\'s Saturday. Saturday, 26th of April and I would like to have a moment of connection with you my dear diary. I am sitting in Maset Terrace and I am on my own. I put Ada on the gym and I\\'m waiting for half an hour to pick her up again and. And then I will go to the reef meeting to discuss about...\",)]'}}\n",
      "Generated Answer:\n",
      "estoy intentando conectar más con la gente real en vez de perderme en mis pensamientos. he estado reflexionando sobre la fragilidad de mi atención y la necesidad de estar presente. últimamente, he tenido algunas noches difíciles, pero me siento un poco mejor. este fin de semana fui al cumpleaños de un amigo y eso me hizo recordar viejos tiempos. quiero dejar de ser paternalista con hogne y dejarla hacer las cosas a su manera. \n",
      "{'generate_answer': {'answer': 'estoy intentando conectar más con la gente real en vez de perderme en mis pensamientos. he estado reflexionando sobre la fragilidad de mi atención y la necesidad de estar presente. últimamente, he tenido algunas noches difíciles, pero me siento un poco mejor. este fin de semana fui al cumpleaños de un amigo y eso me hizo recordar viejos tiempos. quiero dejar de ser paternalista con hogne y dejarla hacer las cosas a su manera. '}}\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\"configurable\": {\"thread_id\": \"33\"}}\n",
    "\n",
    "initial_input = {\n",
    "    \"question\": HumanMessage(\n",
    "        content=(\n",
    "            \"you are a diary drafting assistant with access to my diary entries. \"\n",
    "            \"\"\n",
    "            \"i would like you to send life updates to my parents in spanish.\"\n",
    "            \"draft a short message summarizing what is going on in my life based on latest diary entries. \"\n",
    "            \"please only use the content of the entries to generate the answer. \"\n",
    "            \"do not include any system message nor AI message in the generated answer, just the content of the entries.\"\n",
    "            \"do not include capital letters in the message. \"\n",
    "            \"do make 1 mistake in spelling in the message. \"\n",
    "            \"please speak as if you were me and you are speaking directly to my parents. \"\n",
    "            \"please use coloquial spanish from spain. avoid using latin american spanish. \"\n",
    "            \"please do not mention any dates in the message. just speak as if is today\"\n",
    "            \"do not include introduction sentence. this is going to be a telegram message.\"\n",
    "        )\n",
    "    )\n",
    "}\n",
    "\n",
    "# Stream through the graph until the interrupt\n",
    "for step in graph.stream(initial_input, config, stream_mode=\"updates\"):\n",
    "    if \"generate_answer\" in step:  # Check if the generate_answer node is reached\n",
    "        print(\"Generated Answer:\")\n",
    "        print(step[\"generate_answer\"][\"answer\"])  # Display the answer to the user\n",
    "    print(step)\n",
    "\n",
    "# Ask for user approval to send the message\n",
    "user_approval = input(\"Do you want to send this answer to Telegram? (yes/no): \")\n",
    "\n",
    "# Check user approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    # Continue the graph execution to send the message\n",
    "    for step in graph.stream(None, config, stream_mode=\"values\"):\n",
    "        if \"post_to_telegram\" in step:  # Check if the post_to_telegram node is reached\n",
    "            print(\"Message sent to Telegram.\")\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yc_final 3.9 (venv)",
   "language": "python",
   "name": "venv-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
